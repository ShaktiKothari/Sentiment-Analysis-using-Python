{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the python libraries\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data from a text file\n",
    "\n",
    "with open('data.txt', 'r+') as f:\n",
    "    data = f.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading publicly available list of positive and negative words from text files\n",
    "\n",
    "with open('LM_neg_words.txt', 'r+') as t:\n",
    "    lmneg = t.read() \n",
    "\n",
    "with open('LM_pos_words.txt', 'r+') as p:\n",
    "    lmpos = p.read() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the data using a function from nltk library\n",
    "\n",
    "tokens = tokenizer.tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting all the word tokens into lower case and removing numbers from the token list\n",
    "tokens = [x.lower() for x in tokens]\n",
    "numbers = [s for s in tokens if s.isdigit()]\n",
    "tokens_clean = [x for x in tokens if x not in numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of each word token\n",
    "tokens_fdist = FreqDist(tokens_clean)\n",
    "tokens_df = pd.Series(tokens_fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 words as per the frequency\n",
    "top10_tokens = tokens_df.sort_values(ascending = False)[:10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mojority of high frequency words are stop words, so removing them from overall token list\n",
    "\n",
    "tokens_nostop = [x for x in tokens if x not in list(top10_tokens.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardising the list of positive & negative words by tokenizing then and converting all into lower case\n",
    "\n",
    "lm_pos = tokenizer.tokenize(lmpos)\n",
    "lm_pos = [x.lower() for x in lm_pos]\n",
    "\n",
    "lm_neg = tokenizer.tokenize(lmneg)\n",
    "lm_neg = [x.lower() for x in lm_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmenting postive & negative words in seperate python lists\n",
    "\n",
    "data_pos = [x for x in tokens_nostop if x in lm_pos]\n",
    "data_neg = [x for x in tokens_nostop if x in lm_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Sentiment Score for data\n",
    "\n",
    "sentiment_score = (len(data_pos) - len(data_neg)) / len(tokens_nostop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00223"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative score indicates negative sentiment and positive indicates positive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
